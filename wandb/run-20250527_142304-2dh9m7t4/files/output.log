Number of sequences dropped: 0 out of 10000. (0.00%)

Row‑stochastic transition matrices (pred | true):
   0.7012  0.0741  0.0757  0.0744  0.0745  0.0000   |    0.7000  0.0750  0.0750  0.0750  0.0750  0.0000
   0.0755  0.7016  0.0741  0.0741  0.0748  0.0000   |    0.0750  0.7000  0.0750  0.0750  0.0750  0.0000
   0.0748  0.0733  0.7011  0.0741  0.0767  0.0000   |    0.0750  0.0750  0.7000  0.0750  0.0750  0.0000
   0.0748  0.0764  0.0758  0.6984  0.0746  0.0000   |    0.0750  0.0750  0.0750  0.7000  0.0750  0.0000
   0.0750  0.0742  0.0762  0.0752  0.6994  0.0000   |    0.0750  0.0750  0.0750  0.0750  0.7000  0.0000
   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   |    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
[Data] P_est error: max 0.0017  ‖·‖₁=0.0049 mean_diag=0.5836
[Classifier] epoch 1/30, loss=0.0245
[Classifier] epoch 2/30, loss=0.0020
[Classifier] epoch 3/30, loss=0.0018
[Classifier] epoch 4/30, loss=0.0019
[Classifier] epoch 5/30, loss=0.0268
[Classifier] epoch 6/30, loss=0.0278
[Classifier] epoch 7/30, loss=0.0019
[Classifier] epoch 8/30, loss=0.0515
[Classifier] epoch 9/30, loss=0.0017
[Classifier] epoch 10/30, loss=0.0017
[Classifier] epoch 11/30, loss=0.0019
[Classifier] epoch 12/30, loss=0.0018
[Classifier] epoch 13/30, loss=0.0271
[Classifier] epoch 14/30, loss=0.0018
[Classifier] epoch 15/30, loss=0.0017
[Classifier] epoch 16/30, loss=0.0011
[Classifier] epoch 17/30, loss=0.0023
[Classifier] epoch 18/30, loss=0.0013
[Classifier] epoch 19/30, loss=0.0020
[Classifier] epoch 20/30, loss=0.0011
[Classifier] epoch 21/30, loss=0.0017
[Classifier] epoch 22/30, loss=0.0012
[Classifier] epoch 23/30, loss=0.0010
[Classifier] epoch 24/30, loss=0.0206
[Classifier] epoch 25/30, loss=0.0013
[Classifier] epoch 26/30, loss=0.0020
[Classifier] epoch 27/30, loss=0.0009
[Classifier] epoch 28/30, loss=0.0013
[Classifier] epoch 29/30, loss=0.0029
[Classifier] epoch 30/30, loss=0.0008
[Classifier-Val]  loss = 0.0064  acc = 99.85% TP=10000 FP=16 TN=984 FN=0
[Time‐Cond Classifier] epoch 1/30, BCE=0.3353
[Time‐Cond Classifier] epoch 2/30, BCE=0.1340
[Time‐Cond Classifier] epoch 3/30, BCE=0.1084
[Time‐Cond Classifier] epoch 4/30, BCE=0.1012
[Time‐Cond Classifier] epoch 5/30, BCE=0.1096
[Time‐Cond Classifier] epoch 6/30, BCE=0.0992
[Time‐Cond Classifier] epoch 7/30, BCE=0.1056
[Time‐Cond Classifier] epoch 8/30, BCE=0.1026
[Time‐Cond Classifier] epoch 9/30, BCE=0.1101
[Time‐Cond Classifier] epoch 10/30, BCE=0.1057
[Time‐Cond Classifier] epoch 11/30, BCE=0.1080
[Time‐Cond Classifier] epoch 12/30, BCE=0.1004
[Time‐Cond Classifier] epoch 13/30, BCE=0.1037
[Time‐Cond Classifier] epoch 14/30, BCE=0.1122
[Time‐Cond Classifier] epoch 15/30, BCE=0.1024
[Time‐Cond Classifier] epoch 16/30, BCE=0.1013
[Time‐Cond Classifier] epoch 17/30, BCE=0.0995
[Time‐Cond Classifier] epoch 18/30, BCE=0.1083
[Time‐Cond Classifier] epoch 19/30, BCE=0.1083
[Time‐Cond Classifier] epoch 20/30, BCE=0.1029
[Time‐Cond Classifier] epoch 21/30, BCE=0.1118
[Time‐Cond Classifier] epoch 22/30, BCE=0.1024
[Time‐Cond Classifier] epoch 23/30, BCE=0.1046
[Time‐Cond Classifier] epoch 24/30, BCE=0.1101
[Time‐Cond Classifier] epoch 25/30, BCE=0.1021
[Time‐Cond Classifier] epoch 26/30, BCE=0.1060
[Time‐Cond Classifier] epoch 27/30, BCE=0.1030
[Time‐Cond Classifier] epoch 28/30, BCE=0.0976
[Time‐Cond Classifier] epoch 29/30, BCE=0.1065
[Time‐Cond Classifier] epoch 30/30, BCE=0.1010
[Time-Dependent Classifier-Val]  loss = 0.0100  acc = 99.85% TP=10000 FP=17 TN=983 FN=0
[Denoiser] epoch 1/30 trainCE = 0.9307
[Denoiser] epoch 2/30 trainCE = 0.6334
[Denoiser] epoch 3/30 trainCE = 0.6059
[Denoiser] epoch 4/30 trainCE = 0.6107
[Denoiser] epoch 5/30 trainCE = 0.5929
[Denoiser] epoch 6/30 trainCE = 0.6012
[Denoiser] epoch 7/30 trainCE = 0.6047
[Denoiser] epoch 8/30 trainCE = 0.6090
[Denoiser] epoch 9/30 trainCE = 0.5942
[Denoiser] epoch 10/30 trainCE = 0.5967
[Denoiser] epoch 11/30 trainCE = 0.6034
[Denoiser] epoch 12/30 trainCE = 0.5933
[Denoiser] epoch 13/30 trainCE = 0.6205
[Denoiser] epoch 14/30 trainCE = 0.5939
[Denoiser] epoch 15/30 trainCE = 0.6061
[Denoiser] epoch 16/30 trainCE = 0.6026
[Denoiser] epoch 17/30 trainCE = 0.6010
[Denoiser] epoch 18/30 trainCE = 0.6143
[Denoiser] epoch 19/30 trainCE = 0.5886
[Denoiser] epoch 20/30 trainCE = 0.6062
[Denoiser] epoch 21/30 trainCE = 0.5862
[Denoiser] epoch 22/30 trainCE = 0.5935
[Denoiser] epoch 23/30 trainCE = 0.5928
[Denoiser] epoch 24/30 trainCE = 0.5903
[Denoiser] epoch 25/30 trainCE = 0.6064
[Denoiser] epoch 26/30 trainCE = 0.6063
[Denoiser] epoch 27/30 trainCE = 0.5906
[Denoiser] epoch 28/30 trainCE = 0.5923
[Denoiser] epoch 29/30 trainCE = 0.5983
[Denoiser] epoch 30/30 trainCE = 0.5962
[Ratio‑TD-only-src] epoch 1/1, loss = 31.124391
[Ratio‑TD] epoch 1/30, loss = 35.708889
[Ratio‑TD] epoch 2/30, loss = 12.659622
[Ratio‑TD] epoch 3/30, loss = 7.213865
[Ratio‑TD] epoch 4/30, loss = 6.614599
[Ratio‑TD] epoch 5/30, loss = 6.957396
[Ratio‑TD] epoch 6/30, loss = 7.014990
[Ratio‑TD] epoch 7/30, loss = 6.403658
[Ratio‑TD] epoch 8/30, loss = 6.860684
[Ratio‑TD] epoch 9/30, loss = 6.616872
[Ratio‑TD] epoch 10/30, loss = 6.501627
[Ratio‑TD] epoch 11/30, loss = 6.771570
[Ratio‑TD] epoch 12/30, loss = 6.087799
[Ratio‑TD] epoch 13/30, loss = 6.849398
[Ratio‑TD] epoch 14/30, loss = 6.335245
[Ratio‑TD] epoch 15/30, loss = 7.101686
[Ratio‑TD] epoch 16/30, loss = 6.845883
[Ratio‑TD] epoch 17/30, loss = 6.488964
[Ratio‑TD] epoch 18/30, loss = 6.119246
[Ratio‑TD] epoch 19/30, loss = 6.971076
[Ratio‑TD] epoch 20/30, loss = 6.437603
[Ratio‑TD] epoch 21/30, loss = 6.583085
[Ratio‑TD] epoch 22/30, loss = 6.485086
[Ratio‑TD] epoch 23/30, loss = 6.372734
[Ratio‑TD] epoch 24/30, loss = 6.571258
[Ratio‑TD] epoch 25/30, loss = 6.851291
[Ratio‑TD] epoch 26/30, loss = 6.278259
[Ratio‑TD] epoch 27/30, loss = 6.534348
[Ratio‑TD] epoch 28/30, loss = 6.521513
[Ratio‑TD] epoch 29/30, loss = 6.557062
[Ratio‑TD] epoch 30/30, loss = 6.604987
[Ratio on t-clf + reconstruction loss] epoch  1/1, MSE = 47.605629
[Ratio on t-clf] epoch  1/1, MSE = 18.272056
[Ratio-Reg] epoch 1/1  L_ratio=6.8221  L_cycle=133.3432  L_consistency=0.0000
[Vec-Ratio-TD-full] epoch 1/1, MSE = 3068.775887
Time taken to train ratio net vector: 6.67 seconds
[Ratio estimator] ratio net guided src and tgt trained


[Sampling] gamma=0, type=LRG, ratio_net=no ratio used
Sampling: 100%|██████████| 10/10 [00:02<00:00,  4.13step/s]
Sampled sequences (γ=0), type=LRG, ratio_net=no ratio used
Number of sequences dropped: 57 out of 2048. (2.78%)

Row‑stochastic transition matrices (pred | true):
   0.5637  0.1087  0.1061  0.1025  0.1189  0.0001   |    0.7000  0.0750  0.0750  0.0750  0.0750  0.0000
   0.1094  0.5434  0.1065  0.1179  0.1228  0.0000   |    0.0750  0.7000  0.0750  0.0750  0.0750  0.0000
   0.1077  0.1015  0.5640  0.1107  0.1162  0.0000   |    0.0750  0.0750  0.7000  0.0750  0.0750  0.0000
   0.1018  0.1152  0.1111  0.5585  0.1133  0.0000   |    0.0750  0.0750  0.0750  0.7000  0.0750  0.0000
   0.1132  0.1116  0.1088  0.1011  0.5653  0.0000   |    0.0750  0.0750  0.0750  0.0750  0.7000  0.0000
   1.0000  0.0000  0.0000  0.0000  0.0000  0.0000   |    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
P error max=1.0000  ‖·‖₁=1.0608 mean_diag=0.4658 (t=2.5s)

[Sampling] gamma=1, type=LRG, ratio_net=ratio net guided src and tgt
Sampling:   0%|          | 0/10 [00:20<?, ?step/s]
Traceback (most recent call last):
  File "/Users/juliankleutgens/PycharmProjects/ratio_estimation_synthetic/main2.py", line 464, in <module>
    main()
  File "/Users/juliankleutgens/PycharmProjects/ratio_estimation_synthetic/main2.py", line 444, in main
    samples = sampler.sample(num_of_samples=config.sample_size, device=config.device)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/Users/juliankleutgens/PycharmProjects/ratio_estimation_synthetic/diffusion.py", line 289, in sample
    xt, _, cache = self._rbg_denoise(xt, t, dt, cache)
  File "/Users/juliankleutgens/PycharmProjects/ratio_estimation_synthetic/diffusion.py", line 237, in _rbg_denoise
    log_ratio = self._get_ratio(xt, t)
  File "/Users/juliankleutgens/PycharmProjects/ratio_estimation_synthetic/diffusion.py", line 131, in _get_ratio
    log_ratio = self._batched_ratio(xt, t)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/Users/juliankleutgens/PycharmProjects/ratio_estimation_synthetic/diffusion.py", line 169, in _batched_ratio
    out[start:end] = self.ratio_model(seq_batch,
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/juliankleutgens/PycharmProjects/ratio_estimation_synthetic/models.py", line 133, in forward
    x = layer(x, c)           # [B, L, d]
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/juliankleutgens/PycharmProjects/ratio_estimation_synthetic/models.py", line 81, in forward
    mlp_out = self.mlp(y_mod)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/juliankleutgens/opt/anaconda3/envs/tgdp/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 734, in forward
    return F.gelu(input, approximate=self.approximate)
RuntimeError: MPS backend out of memory (MPS allocated: 3.17 GB, other allocations: 14.85 GB, max allowed: 18.13 GB). Tried to allocate 180.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).
