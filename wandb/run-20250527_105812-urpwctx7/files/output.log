Number of sequences dropped: 0 out of 20000. (0.00%)

Row‑stochastic transition matrices (pred | true):
   0.7012  0.0751  0.0749  0.0743  0.0746  0.0000  0.0000   |    0.7000  0.0750  0.0750  0.0750  0.0750  0.0000  0.0000
   0.0758  0.7011  0.0743  0.0746  0.0742  0.0000  0.0000   |    0.0750  0.7000  0.0750  0.0750  0.0750  0.0000  0.0000
   0.0754  0.0739  0.7006  0.0741  0.0760  0.0000  0.0000   |    0.0750  0.0750  0.7000  0.0750  0.0750  0.0000  0.0000
   0.0756  0.0743  0.0749  0.7003  0.0749  0.0000  0.0000   |    0.0750  0.0750  0.0750  0.7000  0.0750  0.0000  0.0000
   0.0757  0.0743  0.0762  0.0746  0.6991  0.0000  0.0000   |    0.0750  0.0750  0.0750  0.0750  0.7000  0.0000  0.0000
   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   |    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   |    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
[Data] P_est error: max 0.0012  ‖·‖₁=0.0036 mean_diag=0.5003
[Classifier] epoch 1/30, loss=0.0028
[Classifier] epoch 2/30, loss=0.0007
[Classifier] epoch 3/30, loss=0.0005
[Classifier] epoch 4/30, loss=0.0004
[Classifier] epoch 5/30, loss=0.0003
[Classifier] epoch 6/30, loss=0.0003
[Classifier] epoch 7/30, loss=0.0003
[Classifier] epoch 8/30, loss=0.0005
[Classifier] epoch 9/30, loss=0.0322
[Classifier] epoch 10/30, loss=0.0003
[Classifier] epoch 11/30, loss=0.0003
[Classifier] epoch 12/30, loss=0.0003
[Classifier] epoch 13/30, loss=0.0313
[Classifier] epoch 14/30, loss=0.0003
[Classifier] epoch 15/30, loss=0.0003
[Classifier] epoch 16/30, loss=0.0330
[Classifier] epoch 17/30, loss=0.0003
[Classifier] epoch 18/30, loss=0.0003
[Classifier] epoch 19/30, loss=0.0003
[Classifier] epoch 20/30, loss=0.0003
[Classifier] epoch 21/30, loss=0.0002
[Classifier] epoch 22/30, loss=0.0002
[Classifier] epoch 23/30, loss=0.0002
[Classifier] epoch 24/30, loss=0.0003
[Classifier] epoch 25/30, loss=0.0002
[Classifier] epoch 26/30, loss=0.0003
[Classifier] epoch 27/30, loss=0.0002
[Classifier] epoch 28/30, loss=0.0002
[Classifier] epoch 29/30, loss=0.0002
[Classifier] epoch 30/30, loss=0.0002
[Classifier-Val]  loss = 0.0011  acc = 99.99% TP=20000 FP=3 TN=4997 FN=0
[Time‐Cond Classifier] epoch 1/30, BCE=0.3134
[Time‐Cond Classifier] epoch 2/30, BCE=0.1527
[Time‐Cond Classifier] epoch 3/30, BCE=0.1503
[Time‐Cond Classifier] epoch 4/30, BCE=0.1491
[Time‐Cond Classifier] epoch 5/30, BCE=0.1529
[Time‐Cond Classifier] epoch 6/30, BCE=0.1476
[Time‐Cond Classifier] epoch 7/30, BCE=0.1518
[Time‐Cond Classifier] epoch 8/30, BCE=0.1459
[Time‐Cond Classifier] epoch 9/30, BCE=0.1507
[Time‐Cond Classifier] epoch 10/30, BCE=0.1430
[Time‐Cond Classifier] epoch 11/30, BCE=0.1528
[Time‐Cond Classifier] epoch 12/30, BCE=0.1507
[Time‐Cond Classifier] epoch 13/30, BCE=0.1472
[Time‐Cond Classifier] epoch 14/30, BCE=0.1468
[Time‐Cond Classifier] epoch 15/30, BCE=0.1513
[Time‐Cond Classifier] epoch 16/30, BCE=0.1523
[Time‐Cond Classifier] epoch 17/30, BCE=0.1487
[Time‐Cond Classifier] epoch 18/30, BCE=0.1504
[Time‐Cond Classifier] epoch 19/30, BCE=0.1492
[Time‐Cond Classifier] epoch 20/30, BCE=0.1485
[Time‐Cond Classifier] epoch 21/30, BCE=0.1479
[Time‐Cond Classifier] epoch 22/30, BCE=0.1490
[Time‐Cond Classifier] epoch 23/30, BCE=0.1487
[Time‐Cond Classifier] epoch 24/30, BCE=0.1434
[Time‐Cond Classifier] epoch 25/30, BCE=0.1506
[Time‐Cond Classifier] epoch 26/30, BCE=0.1440
[Time‐Cond Classifier] epoch 27/30, BCE=0.1497
[Time‐Cond Classifier] epoch 28/30, BCE=0.1457
[Time‐Cond Classifier] epoch 29/30, BCE=0.1466
[Time‐Cond Classifier] epoch 30/30, BCE=0.1487
[Time-Dependent Classifier-Val]  loss = 0.0011  acc = 99.99% TP=20000 FP=3 TN=4997 FN=0
[Denoiser] epoch 1/30 trainCE = 0.8069
[Denoiser] epoch 2/30 trainCE = 0.6154
[Denoiser] epoch 3/30 trainCE = 0.6072
[Denoiser] epoch 4/30 trainCE = 0.5885
[Denoiser] epoch 5/30 trainCE = 0.5941
[Denoiser] epoch 6/30 trainCE = 0.5930
[Denoiser] epoch 7/30 trainCE = 0.5907
[Denoiser] epoch 8/30 trainCE = 0.6010
[Denoiser] epoch 9/30 trainCE = 0.5918
[Denoiser] epoch 10/30 trainCE = 0.5949
[Denoiser] epoch 11/30 trainCE = 0.5941
[Denoiser] epoch 12/30 trainCE = 0.5967
[Denoiser] epoch 13/30 trainCE = 0.5992
[Denoiser] epoch 14/30 trainCE = 0.5915
[Denoiser] epoch 15/30 trainCE = 0.5894
[Denoiser] epoch 16/30 trainCE = 0.5918
[Denoiser] epoch 17/30 trainCE = 0.5839
[Denoiser] epoch 18/30 trainCE = 0.5908
[Denoiser] epoch 19/30 trainCE = 0.5869
[Denoiser] epoch 20/30 trainCE = 0.5994
[Denoiser] epoch 21/30 trainCE = 0.5981
[Denoiser] epoch 22/30 trainCE = 0.5990
[Denoiser] epoch 23/30 trainCE = 0.5951
[Denoiser] epoch 24/30 trainCE = 0.5993
[Denoiser] epoch 25/30 trainCE = 0.5862
[Denoiser] epoch 26/30 trainCE = 0.6018
[Denoiser] epoch 27/30 trainCE = 0.5912
[Denoiser] epoch 28/30 trainCE = 0.5914
[Denoiser] epoch 29/30 trainCE = 0.5970
[Denoiser] epoch 30/30 trainCE = 0.5964
[Ratio‑TD-only-src] epoch 1/1, loss = 18.963246
[Ratio‑TD] epoch 1/30, loss = 33.725273
[Ratio‑TD] epoch 2/30, loss = 13.535004
[Ratio‑TD] epoch 3/30, loss = 14.114874
[Ratio‑TD] epoch 4/30, loss = 13.555650
[Ratio‑TD] epoch 5/30, loss = 13.631653
[Ratio‑TD] epoch 6/30, loss = 13.471609
[Ratio‑TD] epoch 7/30, loss = 13.627824
[Ratio‑TD] epoch 8/30, loss = 13.994097
[Ratio‑TD] epoch 9/30, loss = 14.032334
[Ratio‑TD] epoch 10/30, loss = 13.340466
[Ratio‑TD] epoch 11/30, loss = 13.809998
[Ratio‑TD] epoch 12/30, loss = 14.030487
[Ratio‑TD] epoch 13/30, loss = 13.869526
[Ratio‑TD] epoch 14/30, loss = 13.389271
[Ratio‑TD] epoch 15/30, loss = 13.756329
[Ratio‑TD] epoch 16/30, loss = 13.635479
[Ratio‑TD] epoch 17/30, loss = 13.760376
[Ratio‑TD] epoch 18/30, loss = 13.927985
[Ratio‑TD] epoch 19/30, loss = 13.773334
[Ratio‑TD] epoch 20/30, loss = 13.842347
[Ratio‑TD] epoch 21/30, loss = 13.546311
[Ratio‑TD] epoch 22/30, loss = 13.711848
[Ratio‑TD] epoch 23/30, loss = 13.807626
[Ratio‑TD] epoch 24/30, loss = 13.921562
[Ratio‑TD] epoch 25/30, loss = 13.667690
[Ratio‑TD] epoch 26/30, loss = 13.871321
[Ratio‑TD] epoch 27/30, loss = 13.564372
[Ratio‑TD] epoch 28/30, loss = 14.407233
[Ratio‑TD] epoch 29/30, loss = 13.824373
[Ratio‑TD] epoch 30/30, loss = 13.796877
[Ratio on t-clf + reconstruction loss] epoch  1/30, MSE = 57.223068
[Ratio on t-clf + reconstruction loss] epoch  2/30, MSE = 35.463137
[Ratio on t-clf + reconstruction loss] epoch  3/30, MSE = 35.098699
[Ratio on t-clf + reconstruction loss] epoch  4/30, MSE = 35.247710
[Ratio on t-clf + reconstruction loss] epoch  5/30, MSE = 35.282196
[Ratio on t-clf + reconstruction loss] epoch  6/30, MSE = 35.292737
[Ratio on t-clf + reconstruction loss] epoch  7/30, MSE = 34.846108
[Ratio on t-clf + reconstruction loss] epoch  8/30, MSE = 34.863373
[Ratio on t-clf + reconstruction loss] epoch  9/30, MSE = 34.886281
[Ratio on t-clf + reconstruction loss] epoch 10/30, MSE = 35.299441
[Ratio on t-clf + reconstruction loss] epoch 11/30, MSE = 35.063665
[Ratio on t-clf + reconstruction loss] epoch 12/30, MSE = 35.180867
[Ratio on t-clf + reconstruction loss] epoch 13/30, MSE = 34.964802
[Ratio on t-clf + reconstruction loss] epoch 14/30, MSE = 34.925776
[Ratio on t-clf + reconstruction loss] epoch 15/30, MSE = 35.036031
[Ratio on t-clf + reconstruction loss] epoch 16/30, MSE = 34.989112
[Ratio on t-clf + reconstruction loss] epoch 17/30, MSE = 35.185052
[Ratio on t-clf + reconstruction loss] epoch 18/30, MSE = 35.169303
[Ratio on t-clf + reconstruction loss] epoch 19/30, MSE = 35.024073
[Ratio on t-clf + reconstruction loss] epoch 20/30, MSE = 35.577307
[Ratio on t-clf + reconstruction loss] epoch 21/30, MSE = 35.094191
[Ratio on t-clf + reconstruction loss] epoch 22/30, MSE = 35.062836
[Ratio on t-clf + reconstruction loss] epoch 23/30, MSE = 35.142865
[Ratio on t-clf + reconstruction loss] epoch 24/30, MSE = 35.164210
[Ratio on t-clf + reconstruction loss] epoch 25/30, MSE = 34.973360
[Ratio on t-clf + reconstruction loss] epoch 26/30, MSE = 35.007016
[Ratio on t-clf + reconstruction loss] epoch 27/30, MSE = 34.960553
[Ratio on t-clf + reconstruction loss] epoch 28/30, MSE = 35.384567
[Ratio on t-clf + reconstruction loss] epoch 29/30, MSE = 34.865529
[Ratio on t-clf + reconstruction loss] epoch 30/30, MSE = 35.272651
[Ratio on t-clf] epoch  1/30, MSE = 16.618995
[Ratio on t-clf] epoch  2/30, MSE = 0.084540
[Ratio on t-clf] epoch  3/30, MSE = 0.056342
[Ratio on t-clf] epoch  4/30, MSE = 0.040194
[Ratio on t-clf] epoch  5/30, MSE = 0.031366
[Ratio on t-clf] epoch  6/30, MSE = 0.026724
[Ratio on t-clf] epoch  7/30, MSE = 0.022848
[Ratio on t-clf] epoch  8/30, MSE = 0.020199
[Ratio on t-clf] epoch  9/30, MSE = 0.019370
[Ratio on t-clf] epoch 10/30, MSE = 0.017411
[Ratio on t-clf] epoch 11/30, MSE = 0.016678
[Ratio on t-clf] epoch 12/30, MSE = 0.016426
[Ratio on t-clf] epoch 13/30, MSE = 0.014698
[Ratio on t-clf] epoch 14/30, MSE = 0.015318
[Ratio on t-clf] epoch 15/30, MSE = 0.014642
[Ratio on t-clf] epoch 16/30, MSE = 0.013864
[Ratio on t-clf] epoch 17/30, MSE = 0.013640
[Ratio on t-clf] epoch 18/30, MSE = 0.012844
[Ratio on t-clf] epoch 19/30, MSE = 0.012298
[Ratio on t-clf] epoch 20/30, MSE = 0.013467
[Ratio on t-clf] epoch 21/30, MSE = 0.012086
[Ratio on t-clf] epoch 22/30, MSE = 0.011000
[Ratio on t-clf] epoch 23/30, MSE = 0.011493
[Ratio on t-clf] epoch 24/30, MSE = 0.010262
[Ratio on t-clf] epoch 25/30, MSE = 0.010506
[Ratio on t-clf] epoch 26/30, MSE = 0.011639
[Ratio on t-clf] epoch 27/30, MSE = 0.011421
[Ratio on t-clf] epoch 28/30, MSE = 0.010148
[Ratio on t-clf] epoch 29/30, MSE = 0.010010
[Ratio on t-clf] epoch 30/30, MSE = 0.009093
[Ratio-Reg] epoch 1/1  L_ratio=0.6629  L_cycle=16.9231  L_consistency=0.0000
[Vec-Ratio-TD-full] epoch 1/1, MSE = 918.163823
Time taken to train ratio net vector: 16.68 seconds
[Ratio estimator] ratio net guided src and tgt trained

[Ratio estimator] ratio net scaler on t-classifer trained

[Ratio estimator] ratio net scaler on t-classifer + reconstruction trained


[Sampling] gamma=0, type=LRG, ratio_net=no ratio used
Sampling: 100%|██████████| 20/20 [00:04<00:00,  4.74step/s]
Sampled sequences (γ=0), type=LRG, ratio_net=no ratio used
Number of sequences dropped: 52 out of 2048. (2.54%)

Row‑stochastic transition matrices (pred | true):
   0.5873  0.1112  0.0914  0.1034  0.1067  0.0000  0.0000   |    0.7000  0.0750  0.0750  0.0750  0.0750  0.0000  0.0000
   0.0973  0.6235  0.0887  0.0926  0.0978  0.0000  0.0000   |    0.0750  0.7000  0.0750  0.0750  0.0750  0.0000  0.0000
   0.1026  0.1051  0.5811  0.1023  0.1087  0.0000  0.0001   |    0.0750  0.0750  0.7000  0.0750  0.0750  0.0000  0.0000
   0.0974  0.0944  0.0796  0.6356  0.0930  0.0000  0.0000   |    0.0750  0.0750  0.0750  0.7000  0.0750  0.0000  0.0000
   0.0997  0.0933  0.0903  0.0973  0.6194  0.0000  0.0000   |    0.0750  0.0750  0.0750  0.0750  0.7000  0.0000  0.0000
   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   |    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
   0.0000  0.0000  1.0000  0.0000  0.0000  0.0000  0.0000   |    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
P error max=1.0000  ‖·‖₁=1.0270 mean_diag=0.4353 (t=4.3s)

[Sampling] gamma=1, type=LRG, ratio_net=ratio net guided src and tgt
Sampling: 100%|██████████| 20/20 [07:58<00:00, 23.91s/step]
The mean difference between the mask and token log-ratios is 3.350969076156616
The mean difference between the mask and token log-ratios is 3.364295721054077
The mean difference between the mask and token log-ratios is 3.3770720958709717
The mean difference between the mask and token log-ratios is 2.855465888977051
The mean difference between the mask and token log-ratios is 0.004277605097740889
The mean difference between the mask and token log-ratios is 0.006428857799619436
The mean difference between the mask and token log-ratios is 0.010563898831605911
The mean difference between the mask and token log-ratios is 0.014995208010077477
The mean difference between the mask and token log-ratios is 0.01980767771601677
The mean difference between the mask and token log-ratios is 0.023575948551297188
The mean difference between the mask and token log-ratios is 0.026016419753432274
The mean difference between the mask and token log-ratios is 0.027431489899754524
The mean difference between the mask and token log-ratios is 0.0280300360172987
The mean difference between the mask and token log-ratios is 0.028107432648539543
The mean difference between the mask and token log-ratios is 0.028034014627337456
The mean difference between the mask and token log-ratios is 0.027918566018342972
The mean difference between the mask and token log-ratios is 0.027762876823544502
The mean difference between the mask and token log-ratios is 0.02766946330666542
The mean difference between the mask and token log-ratios is 0.027570750564336777
The mean difference between the mask and token log-ratios is 0.027513163164258003
Sampled sequences (γ=1), type=LRG, ratio_net=ratio net guided src and tgt
Number of sequences dropped: 57 out of 2048. (2.78%)

Row‑stochastic transition matrices (pred | true):
   0.4632  0.0845  0.0805  0.0826  0.0801  0.1114  0.0976   |    0.4000  0.1000  0.1000  0.1000  0.1000  0.1000  0.1000
   0.0697  0.4984  0.0671  0.0686  0.0738  0.1183  0.1041   |    0.1000  0.4000  0.1000  0.1000  0.1000  0.1000  0.1000
   0.0587  0.0615  0.4538  0.0613  0.0691  0.1365  0.1590   |    0.1000  0.1000  0.4000  0.1000  0.1000  0.1000  0.1000
   0.0601  0.0679  0.0694  0.5044  0.0587  0.1159  0.1236   |    0.1000  0.1000  0.1000  0.4000  0.1000  0.1000  0.1000
   0.0638  0.0726  0.0744  0.0672  0.5043  0.1241  0.0937   |    0.1000  0.1000  0.1000  0.1000  0.4000  0.1000  0.1000
   0.1129  0.1333  0.1740  0.1508  0.1509  0.1421  0.1359   |    0.1000  0.1000  0.1000  0.1000  0.1000  0.4000  0.1000
   0.0976  0.1301  0.2129  0.1576  0.1177  0.1467  0.1373   |    0.1000  0.1000  0.1000  0.1000  0.1000  0.1000  0.4000
P error max=0.2627  ‖·‖₁=0.4827 mean_diag=0.3862 (t=478.2s)

[Sampling] gamma=1, type=LRG, ratio_net=ratio net scaler on t-classifer
Sampling: 100%|██████████| 20/20 [08:02<00:00, 24.13s/step]
The mean difference between the mask and token log-ratios is 2.0130536556243896
The mean difference between the mask and token log-ratios is 2.041426181793213
The mean difference between the mask and token log-ratios is 2.069655656814575
The mean difference between the mask and token log-ratios is 2.0961949825286865
The mean difference between the mask and token log-ratios is 2.0791759490966797
The mean difference between the mask and token log-ratios is 1.7561250925064087
The mean difference between the mask and token log-ratios is 1.0021449327468872
The mean difference between the mask and token log-ratios is 0.41738346219062805
The mean difference between the mask and token log-ratios is 0.3359988033771515
The mean difference between the mask and token log-ratios is 0.35647159814834595
The mean difference between the mask and token log-ratios is 0.37180349230766296
The mean difference between the mask and token log-ratios is 0.38315901160240173
The mean difference between the mask and token log-ratios is 0.3910715878009796
The mean difference between the mask and token log-ratios is 0.3970130383968353
The mean difference between the mask and token log-ratios is 0.4014137387275696
The mean difference between the mask and token log-ratios is 0.404940128326416
The mean difference between the mask and token log-ratios is 0.40774306654930115
The mean difference between the mask and token log-ratios is 0.41018444299697876
The mean difference between the mask and token log-ratios is 0.4123314619064331
The mean difference between the mask and token log-ratios is 0.41443130373954773
Sampled sequences (γ=1), type=LRG, ratio_net=ratio net scaler on t-classifer
Number of sequences dropped: 53 out of 2048. (2.59%)

Row‑stochastic transition matrices (pred | true):
   0.5636  0.0951  0.0840  0.1012  0.0976  0.0261  0.0324   |    0.4000  0.1000  0.1000  0.1000  0.1000  0.1000  0.1000
   0.0862  0.5936  0.0799  0.0858  0.0933  0.0293  0.0319   |    0.1000  0.4000  0.1000  0.1000  0.1000  0.1000  0.1000
   0.0879  0.0894  0.5481  0.0914  0.1042  0.0330  0.0462   |    0.1000  0.1000  0.4000  0.1000  0.1000  0.1000  0.1000
   0.0846  0.0874  0.0778  0.5975  0.0891  0.0287  0.0349   |    0.1000  0.1000  0.1000  0.4000  0.1000  0.1000  0.1000
   0.0887  0.0864  0.0786  0.0911  0.6003  0.0288  0.0262   |    0.1000  0.1000  0.1000  0.1000  0.4000  0.1000  0.1000
   0.1561  0.1920  0.1926  0.2073  0.1920  0.0283  0.0318   |    0.1000  0.1000  0.1000  0.1000  0.1000  0.4000  0.1000
   0.1546  0.1807  0.2170  0.2098  0.1673  0.0394  0.0312   |    0.1000  0.1000  0.1000  0.1000  0.1000  0.1000  0.4000
P error max=0.3717  ‖·‖₁=0.7602 mean_diag=0.4232 (t=482.6s)

[Sampling] gamma=1, type=LRG, ratio_net=ratio net scaler on t-classifer + reconstruction
Sampling: 100%|██████████| 20/20 [08:03<00:00, 24.15s/step]
The mean difference between the mask and token log-ratios is 1.3649365901947021
The mean difference between the mask and token log-ratios is 1.3752493858337402
The mean difference between the mask and token log-ratios is 1.3854490518569946
The mean difference between the mask and token log-ratios is 1.3947747945785522
The mean difference between the mask and token log-ratios is 1.3360458612442017
The mean difference between the mask and token log-ratios is 1.0266189575195312
The mean difference between the mask and token log-ratios is 1.054911494255066
The mean difference between the mask and token log-ratios is 1.2902661561965942
The mean difference between the mask and token log-ratios is 1.4952627420425415
The mean difference between the mask and token log-ratios is 1.6187323331832886
The mean difference between the mask and token log-ratios is 1.676101803779602
The mean difference between the mask and token log-ratios is 1.6895825862884521
The mean difference between the mask and token log-ratios is 1.6887439489364624
The mean difference between the mask and token log-ratios is 1.688347339630127
The mean difference between the mask and token log-ratios is 1.695705533027649
The mean difference between the mask and token log-ratios is 1.6920115947723389
The mean difference between the mask and token log-ratios is 1.6930491924285889
The mean difference between the mask and token log-ratios is 1.6958211660385132
The mean difference between the mask and token log-ratios is 1.7050215005874634
The mean difference between the mask and token log-ratios is 1.7106120586395264
Sampled sequences (γ=1), type=LRG, ratio_net=ratio net scaler on t-classifer + reconstruction
Number of sequences dropped: 68 out of 2048. (3.32%)

Row‑stochastic transition matrices (pred | true):
   0.5237  0.1587  0.0965  0.1038  0.1033  0.0068  0.0071   |    0.4000  0.1000  0.1000  0.1000  0.1000  0.1000  0.1000
   0.0502  0.7169  0.0773  0.0771  0.0697  0.0039  0.0049   |    0.1000  0.4000  0.1000  0.1000  0.1000  0.1000  0.1000
   0.0562  0.1439  0.6117  0.0869  0.0900  0.0049  0.0062   |    0.1000  0.1000  0.4000  0.1000  0.1000  0.1000  0.1000
   0.0580  0.1352  0.0849  0.6221  0.0892  0.0048  0.0058   |    0.1000  0.1000  0.1000  0.4000  0.1000  0.1000  0.1000
   0.0631  0.1389  0.0915  0.0882  0.6070  0.0052  0.0060   |    0.1000  0.1000  0.1000  0.1000  0.4000  0.1000  0.1000
   0.1502  0.2271  0.1758  0.2125  0.2344  0.0000  0.0000   |    0.1000  0.1000  0.1000  0.1000  0.1000  0.4000  0.1000
   0.1411  0.2945  0.2117  0.1380  0.2147  0.0000  0.0000   |    0.1000  0.1000  0.1000  0.1000  0.1000  0.1000  0.4000
P error max=0.4000  ‖·‖₁=0.9067 mean_diag=0.4402 (t=483.1s)

[Sampling] gamma=1, type=PLG, ratio_net=ratio net guided src and tgt
Sampling:  20%|██        | 4/20 [01:36<06:26, 24.14s/step]
The mean difference between the mask and token log-ratios is 3.350969076156616
The mean difference between the mask and token log-ratios is 3.364295721054077
The mean difference between the mask and token log-ratios is 3.3770720958709717
The mean difference between the mask and token log-ratios is 3.388734817504883
