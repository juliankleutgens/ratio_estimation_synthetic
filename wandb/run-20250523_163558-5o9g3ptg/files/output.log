Number of sequences dropped: 0 out of 20000. (0.00%)

Row‑stochastic transition matrices (pred | true):
   0.7012  0.0751  0.0749  0.0743  0.0746  0.0000   |    0.7000  0.0750  0.0750  0.0750  0.0750  0.0000
   0.0758  0.7011  0.0743  0.0746  0.0742  0.0000   |    0.0750  0.7000  0.0750  0.0750  0.0750  0.0000
   0.0754  0.0739  0.7006  0.0741  0.0760  0.0000   |    0.0750  0.0750  0.7000  0.0750  0.0750  0.0000
   0.0756  0.0743  0.0749  0.7003  0.0749  0.0000   |    0.0750  0.0750  0.0750  0.7000  0.0750  0.0000
   0.0757  0.0743  0.0762  0.0746  0.6991  0.0000   |    0.0750  0.0750  0.0750  0.0750  0.7000  0.0000
   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   |    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
[Data] P_est error: max 0.0012  ‖·‖₁=0.0036 mean_diag=0.5837
[Classifier] epoch 1/30, loss=0.0255
[Classifier] epoch 2/30, loss=0.0037
[Classifier] epoch 3/30, loss=0.0252
[Classifier] epoch 4/30, loss=0.0030
[Classifier] epoch 5/30, loss=0.0248
[Classifier] epoch 6/30, loss=0.0036
[Classifier] epoch 7/30, loss=0.0430
[Classifier] epoch 8/30, loss=0.0028
[Classifier] epoch 9/30, loss=0.0042
[Classifier] epoch 10/30, loss=0.0251
[Classifier] epoch 11/30, loss=0.0626
[Classifier] epoch 12/30, loss=0.0197
[Classifier] epoch 13/30, loss=0.0006
[Classifier] epoch 14/30, loss=0.0019
[Classifier] epoch 15/30, loss=0.0063
[Classifier] epoch 16/30, loss=0.0224
[Classifier] epoch 17/30, loss=0.0199
[Classifier] epoch 18/30, loss=0.0102
[Classifier] epoch 19/30, loss=0.0427
[Classifier] epoch 20/30, loss=0.0246
[Classifier] epoch 21/30, loss=0.0009
[Classifier] epoch 22/30, loss=0.0032
[Classifier] epoch 23/30, loss=0.0075
[Classifier] epoch 24/30, loss=0.0016
[Classifier] epoch 25/30, loss=0.0013
[Classifier] epoch 26/30, loss=0.0248
[Classifier] epoch 27/30, loss=0.0055
[Classifier] epoch 28/30, loss=0.0215
[Classifier] epoch 29/30, loss=0.0016
[Classifier] epoch 30/30, loss=0.0011
[Classifier-Val]  loss = 0.0076  acc = 99.76% TP=19999 FP=59 TN=4941 FN=1
[Time‐Cond Classifier] epoch 1/30, BCE=0.3312
[Time‐Cond Classifier] epoch 2/30, BCE=0.1855
[Time‐Cond Classifier] epoch 3/30, BCE=0.1834
[Time‐Cond Classifier] epoch 4/30, BCE=0.1789
[Time‐Cond Classifier] epoch 5/30, BCE=0.1837
[Time‐Cond Classifier] epoch 6/30, BCE=0.1797
[Time‐Cond Classifier] epoch 7/30, BCE=0.1805
[Time‐Cond Classifier] epoch 8/30, BCE=0.1828
[Time‐Cond Classifier] epoch 9/30, BCE=0.1782
[Time‐Cond Classifier] epoch 10/30, BCE=0.1817
[Time‐Cond Classifier] epoch 11/30, BCE=0.1780
[Time‐Cond Classifier] epoch 12/30, BCE=0.1833
[Time‐Cond Classifier] epoch 13/30, BCE=0.1755
[Time‐Cond Classifier] epoch 14/30, BCE=0.1780
[Time‐Cond Classifier] epoch 15/30, BCE=0.1777
[Time‐Cond Classifier] epoch 16/30, BCE=0.1811
[Time‐Cond Classifier] epoch 17/30, BCE=0.1810
[Time‐Cond Classifier] epoch 18/30, BCE=0.1784
[Time‐Cond Classifier] epoch 19/30, BCE=0.1767
[Time‐Cond Classifier] epoch 20/30, BCE=0.1797
[Time‐Cond Classifier] epoch 21/30, BCE=0.1771
[Time‐Cond Classifier] epoch 22/30, BCE=0.1776
[Time‐Cond Classifier] epoch 23/30, BCE=0.1805
[Time‐Cond Classifier] epoch 24/30, BCE=0.1751
[Time‐Cond Classifier] epoch 25/30, BCE=0.1804
[Time‐Cond Classifier] epoch 26/30, BCE=0.1702
[Time‐Cond Classifier] epoch 27/30, BCE=0.1721
[Time‐Cond Classifier] epoch 28/30, BCE=0.1728
[Time‐Cond Classifier] epoch 29/30, BCE=0.1709
[Time‐Cond Classifier] epoch 30/30, BCE=0.1765
[Time-Dependent Classifier-Val]  loss = 0.0135  acc = 99.66% TP=19995 FP=81 TN=4919 FN=5
[Denoiser] epoch 1/30 trainCE = 0.7854
[Denoiser] epoch 2/30 trainCE = 0.6160
[Denoiser] epoch 3/30 trainCE = 0.6075
[Denoiser] epoch 4/30 trainCE = 0.5892
[Denoiser] epoch 5/30 trainCE = 0.5944
[Denoiser] epoch 6/30 trainCE = 0.5928
[Denoiser] epoch 7/30 trainCE = 0.5919
[Denoiser] epoch 8/30 trainCE = 0.6031
[Denoiser] epoch 9/30 trainCE = 0.5926
[Denoiser] epoch 10/30 trainCE = 0.5935
[Denoiser] epoch 11/30 trainCE = 0.5939
[Denoiser] epoch 12/30 trainCE = 0.5964
[Denoiser] epoch 13/30 trainCE = 0.6002
[Denoiser] epoch 14/30 trainCE = 0.5932
[Denoiser] epoch 15/30 trainCE = 0.5900
[Denoiser] epoch 16/30 trainCE = 0.5931
[Denoiser] epoch 17/30 trainCE = 0.5841
[Denoiser] epoch 18/30 trainCE = 0.5919
[Denoiser] epoch 19/30 trainCE = 0.5871
[Denoiser] epoch 20/30 trainCE = 0.5995
[Denoiser] epoch 21/30 trainCE = 0.5980
[Denoiser] epoch 22/30 trainCE = 0.5994
[Denoiser] epoch 23/30 trainCE = 0.5953
[Denoiser] epoch 24/30 trainCE = 0.5992
[Denoiser] epoch 25/30 trainCE = 0.5868
[Denoiser] epoch 26/30 trainCE = 0.6013
[Denoiser] epoch 27/30 trainCE = 0.5918
[Denoiser] epoch 28/30 trainCE = 0.5915
[Denoiser] epoch 29/30 trainCE = 0.5963
[Denoiser] epoch 30/30 trainCE = 0.5974
[Ratio‑TD-only-src] epoch 1/1, loss = 18.644586
[Ratio‑TD] epoch 1/3, loss = 36.766030
[Ratio‑TD] epoch 2/3, loss = 17.071111
[Ratio‑TD] epoch 3/3, loss = 17.124066
[Ratio on t-clf + reconstruction loss] epoch  1/1, MSE = 72.137283
[Ratio on t-clf] epoch  1/2, MSE = 20.904032
[Ratio on t-clf] epoch  2/2, MSE = 1.258736
[Ratio-Reg] epoch 1/1  L_ratio=1.9848  L_cycle=21.7128  L_consistency=0.0000
[Vec-Ratio-TD-full] epoch 1/1, MSE = 1035.907077
Time taken to train ratio net vector: 15.60 seconds
[Ratio estimator] ratio net guided src and tgt trained

[Ratio estimator] ratio net scaler on t-classifer trained


[Sampling] gamma=0, type=LRG, ratio_net=no ratio used
Sampling: 100%|██████████| 20/20 [00:04<00:00,  4.77step/s]
Sampled sequences (γ=0), type=LRG, ratio_net=no ratio used
Number of sequences dropped: 69 out of 2048. (3.37%)

Row‑stochastic transition matrices (pred | true):
   0.6523  0.0840  0.0855  0.0884  0.0899  0.0000   |    0.7000  0.0750  0.0750  0.0750  0.0750  0.0000
   0.0967  0.6289  0.0904  0.0909  0.0931  0.0001   |    0.0750  0.7000  0.0750  0.0750  0.0750  0.0000
   0.0987  0.0931  0.6195  0.0906  0.0981  0.0000   |    0.0750  0.0750  0.7000  0.0750  0.0750  0.0000
   0.0873  0.0830  0.0787  0.6378  0.1132  0.0000   |    0.0750  0.0750  0.0750  0.7000  0.0750  0.0000
   0.0871  0.0781  0.0845  0.1090  0.6413  0.0000   |    0.0750  0.0750  0.0750  0.0750  0.7000  0.0000
   1.0000  0.0000  0.0000  0.0000  0.0000  0.0000   |    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
P error max=1.0000  ‖·‖₁=1.0138 mean_diag=0.5300 (t=4.3s)

[Sampling] gamma=1, type=LRG, ratio_net=ratio net guided src and tgt
Sampling: 100%|██████████| 20/20 [07:10<00:00, 21.55s/step]
The mean difference between the mask and token log-ratios is 1.9446525573730469
The mean difference between the mask and token log-ratios is 1.9495736360549927
The mean difference between the mask and token log-ratios is 1.9523916244506836
The mean difference between the mask and token log-ratios is 1.257392406463623
The mean difference between the mask and token log-ratios is -0.01114650722593069
The mean difference between the mask and token log-ratios is -0.007407239638268948
The mean difference between the mask and token log-ratios is 0.0017674973933026195
The mean difference between the mask and token log-ratios is 0.010662619955837727
The mean difference between the mask and token log-ratios is 0.016478538513183594
The mean difference between the mask and token log-ratios is 0.01974458433687687
The mean difference between the mask and token log-ratios is 0.02156843990087509
The mean difference between the mask and token log-ratios is 0.02257763035595417
The mean difference between the mask and token log-ratios is 0.023156488314270973
The mean difference between the mask and token log-ratios is 0.023502174764871597
The mean difference between the mask and token log-ratios is 0.023727895691990852
The mean difference between the mask and token log-ratios is 0.02384776435792446
The mean difference between the mask and token log-ratios is 0.023917067795991898
The mean difference between the mask and token log-ratios is 0.02395988628268242
The mean difference between the mask and token log-ratios is 0.02398700825870037
The mean difference between the mask and token log-ratios is 0.02399391122162342
Sampled sequences (γ=1), type=LRG, ratio_net=ratio net guided src and tgt
Number of sequences dropped: 44 out of 2048. (2.15%)

Row‑stochastic transition matrices (pred | true):
   0.4615  0.0523  0.0482  0.0558  0.0679  0.3144   |    0.4000  0.1200  0.1200  0.1200  0.1200  0.1200
   0.0841  0.4991  0.0731  0.0749  0.0836  0.1852   |    0.1200  0.4000  0.1200  0.1200  0.1200  0.1200
   0.0801  0.0623  0.5118  0.0710  0.1014  0.1734   |    0.1200  0.1200  0.4000  0.1200  0.1200  0.1200
   0.0725  0.0583  0.0577  0.5121  0.0942  0.2052   |    0.1200  0.1200  0.1200  0.4000  0.1200  0.1200
   0.0678  0.0472  0.0505  0.0713  0.4818  0.2813   |    0.1200  0.1200  0.1200  0.1200  0.4000  0.1200
   0.1877  0.0608  0.0590  0.0899  0.1668  0.4357   |    0.1200  0.1200  0.1200  0.1200  0.1200  0.4000
P error max=0.1944  ‖·‖₁=0.4434 mean_diag=0.4837 (t=431.0s)

[Sampling] gamma=1, type=LRG, ratio_net=ratio net scaler on t-classifer
Sampling:  15%|█▌        | 3/20 [01:04<06:04, 21.41s/step]
The mean difference between the mask and token log-ratios is 1.6147836446762085
The mean difference between the mask and token log-ratios is 1.625948429107666
The mean difference between the mask and token log-ratios is 1.6368513107299805
